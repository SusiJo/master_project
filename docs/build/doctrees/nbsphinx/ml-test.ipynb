{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import read_tpm, read_metadata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold, GridSearchCV\n",
    "\n",
    "# scores\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, balanced_accuracy_score, f1_score, matthews_corrcoef\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer\n",
    "\n",
    "# classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "inpath = \"/Users/susanne/Documents/Master/TPM_TCGA_PAAD_GTEX_pancreas.txt\"\n",
    "metadata = \"/Users/susanne/Documents/Datasets_Metadata/new_TCGA_PAAD_metadata.csv\"\n",
    "sample_ids, gene_ids, feature_names, raw_data = read_tpm(inpath)\n",
    "\n",
    "# Convert data to numpy array\n",
    "data_arr = np.array(raw_data, dtype=float)\n",
    "# Transpose (n_samples, n_features)\n",
    "data = np.transpose(data_arr)\n",
    "\n",
    "# METADATA\n",
    "labels, target, target_names = read_metadata(metadata, sample_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Split Test / Train\n",
    "Using all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Split Train and Test data (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 2 Classifiers: SVM, RandomForest Grid Search\n",
    " \n",
    "Grid Search already performs cross validation of the training data in smaller folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'C': 0.1}\n",
      "Best estimator:  LinearSVC(C=0.1)\n",
      "Best params:  {'max_features': 500, 'n_estimators': 10}\n",
      "Best estimator:  RandomForestClassifier(max_features=500, n_estimators=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "      <th>Gene ID</th>\n",
       "      <th>Gene Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098663</td>\n",
       "      <td>ENSG00000171877</td>\n",
       "      <td>FRMD5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.098647</td>\n",
       "      <td>ENSG00000227376</td>\n",
       "      <td>FTH1P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.096065</td>\n",
       "      <td>ENSG00000214653</td>\n",
       "      <td>HNRNPA3P3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.096062</td>\n",
       "      <td>ENSG00000242262</td>\n",
       "      <td>RP11-100N21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.095996</td>\n",
       "      <td>ENSG00000228797</td>\n",
       "      <td>FAM207BP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63670</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>C1orf112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63671</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>SCYL3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63672</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>DPM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63673</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>TNMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63674</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>TSPAN6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63675 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature Importance          Gene ID      Gene Name\n",
       "0                0.098663  ENSG00000171877          FRMD5\n",
       "1                0.098647  ENSG00000227376        FTH1P16\n",
       "2                0.096065  ENSG00000214653      HNRNPA3P3\n",
       "3                0.096062  ENSG00000242262  RP11-100N21.1\n",
       "4                0.095996  ENSG00000228797       FAM207BP\n",
       "...                   ...              ...            ...\n",
       "63670            0.000000  ENSG00000000460       C1orf112\n",
       "63671            0.000000  ENSG00000000457          SCYL3\n",
       "63672            0.000000  ENSG00000000419           DPM1\n",
       "63673            0.000000  ENSG00000000005           TNMD\n",
       "63674            0.000000  ENSG00000000003         TSPAN6\n",
       "\n",
       "[63675 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorers = {'matthews': make_scorer(matthews_corrcoef),\n",
    "          'balanced': make_scorer(balanced_accuracy_score)}\n",
    "\n",
    "######################################################################################################\n",
    "# LINEAR SVC\n",
    "\n",
    "svc_clf = LinearSVC()\n",
    "svc_grid = [ {'C': np.linspace(0.1, 1.0, num=10)} ]\n",
    "svc_search = GridSearchCV(svc_clf, svc_grid, cv=5, return_train_score=True)   #, scoring=make_scorer(matthews_corrcoef)\n",
    "svc_search.fit(scaled_X_train, y_train)\n",
    "print(\"Best params: \", svc_search.best_params_)\n",
    "print(\"Best estimator: \", svc_search.best_estimator_)\n",
    "svc_cvres = pd.DataFrame.from_dict(svc_search.cv_results_)\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "# RANDOM FOREST\n",
    "forest_clf = RandomForestClassifier()\n",
    "tree_grid = [ {'n_estimators':[5, 10, 20, 50, 100], 'max_features':[5, 10, 20, 50, 100, 200, 500]} ]\n",
    "tree_search = GridSearchCV(forest_clf, tree_grid, cv=5, return_train_score=True) # , scoring=make_scorer(matthews_corrcoef)\n",
    "tree_search.fit(scaled_X_train, y_train)\n",
    "print(\"Best params: \", tree_search.best_params_)\n",
    "print(\"Best estimator: \", tree_search.best_estimator_)\n",
    "\n",
    "# cross_val_scores available for each combination\n",
    "tree_cvres = pd.DataFrame.from_dict(tree_search.cv_results_)\n",
    "\n",
    "    \n",
    "# extract feature importances: which genes most informative?\n",
    "tree_feature_importances = tree_search.best_estimator_.feature_importances_\n",
    "\n",
    "# print(most important features with their names)\n",
    "df_tree_feature_importances = pd.DataFrame(sorted(zip(tree_feature_importances, gene_ids, feature_names), reverse=True), columns=['Feature Importance', 'Gene ID', 'Gene Name'])\n",
    "df_tree_feature_importances\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'C': 0.1}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'C': 0.2}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'C': 0.30000000000000004}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'C': 0.4}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'C': 0.5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'C': 0.6}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'C': 0.7000000000000001}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'C': 0.8}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'C': 0.9}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'C': 1.0}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       params  split0_test_score  split1_test_score  \\\n",
       "0                  {'C': 0.1}                1.0                1.0   \n",
       "1                  {'C': 0.2}                1.0                1.0   \n",
       "2  {'C': 0.30000000000000004}                1.0                1.0   \n",
       "3                  {'C': 0.4}                1.0                1.0   \n",
       "4                  {'C': 0.5}                1.0                1.0   \n",
       "5                  {'C': 0.6}                1.0                1.0   \n",
       "6   {'C': 0.7000000000000001}                1.0                1.0   \n",
       "7                  {'C': 0.8}                1.0                1.0   \n",
       "8                  {'C': 0.9}                1.0                1.0   \n",
       "9                  {'C': 1.0}                1.0                1.0   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  mean_test_score  \\\n",
       "0                1.0           0.966667           0.966102         0.986554   \n",
       "1                1.0           0.966667           0.966102         0.986554   \n",
       "2                1.0           0.966667           0.966102         0.986554   \n",
       "3                1.0           0.966667           0.966102         0.986554   \n",
       "4                1.0           0.966667           0.966102         0.986554   \n",
       "5                1.0           0.966667           0.966102         0.986554   \n",
       "6                1.0           0.966667           0.966102         0.986554   \n",
       "7                1.0           0.966667           0.966102         0.986554   \n",
       "8                1.0           0.966667           0.966102         0.986554   \n",
       "9                1.0           0.966667           0.966102         0.986554   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.016469                1                 1.0                 1.0   \n",
       "1        0.016469                1                 1.0                 1.0   \n",
       "2        0.016469                1                 1.0                 1.0   \n",
       "3        0.016469                1                 1.0                 1.0   \n",
       "4        0.016469                1                 1.0                 1.0   \n",
       "5        0.016469                1                 1.0                 1.0   \n",
       "6        0.016469                1                 1.0                 1.0   \n",
       "7        0.016469                1                 1.0                 1.0   \n",
       "8        0.016469                1                 1.0                 1.0   \n",
       "9        0.016469                1                 1.0                 1.0   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0                 1.0                 1.0                 1.0   \n",
       "1                 1.0                 1.0                 1.0   \n",
       "2                 1.0                 1.0                 1.0   \n",
       "3                 1.0                 1.0                 1.0   \n",
       "4                 1.0                 1.0                 1.0   \n",
       "5                 1.0                 1.0                 1.0   \n",
       "6                 1.0                 1.0                 1.0   \n",
       "7                 1.0                 1.0                 1.0   \n",
       "8                 1.0                 1.0                 1.0   \n",
       "9                 1.0                 1.0                 1.0   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0               1.0              0.0  \n",
       "1               1.0              0.0  \n",
       "2               1.0              0.0  \n",
       "3               1.0              0.0  \n",
       "4               1.0              0.0  \n",
       "5               1.0              0.0  \n",
       "6               1.0              0.0  \n",
       "7               1.0              0.0  \n",
       "8               1.0              0.0  \n",
       "9               1.0              0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_cvres.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_features': 5, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.962994</td>\n",
       "      <td>0.040539</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.003742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_features': 5, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.969718</td>\n",
       "      <td>0.032786</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>0.003130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_features': 5, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_features': 5, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_features': 5, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_features': 10, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.966384</td>\n",
       "      <td>0.030290</td>\n",
       "      <td>34</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.995819</td>\n",
       "      <td>0.004583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'max_features': 10, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.973107</td>\n",
       "      <td>0.025308</td>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'max_features': 10, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.976384</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'max_features': 10, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'max_features': 10, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'max_features': 20, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.979831</td>\n",
       "      <td>0.019699</td>\n",
       "      <td>21</td>\n",
       "      <td>0.987448</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.994146</td>\n",
       "      <td>0.003349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'max_features': 20, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.976441</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.003347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'max_features': 20, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'max_features': 20, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'max_features': 20, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'max_features': 50, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.973051</td>\n",
       "      <td>0.034787</td>\n",
       "      <td>32</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.997493</td>\n",
       "      <td>0.003346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'max_features': 50, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.976384</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>29</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'max_features': 50, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.979774</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'max_features': 50, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.979774</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>24</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'max_features': 50, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'max_features': 100, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.986497</td>\n",
       "      <td>0.019757</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'max_features': 100, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.976441</td>\n",
       "      <td>0.029398</td>\n",
       "      <td>26</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>0.003130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>{'max_features': 100, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.002050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'max_features': 100, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>{'max_features': 100, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>{'max_features': 200, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.979831</td>\n",
       "      <td>0.019699</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.991632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.996656</td>\n",
       "      <td>0.003130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>{'max_features': 200, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.976441</td>\n",
       "      <td>0.025338</td>\n",
       "      <td>26</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>{'max_features': 200, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>{'max_features': 200, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999163</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>{'max_features': 200, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'max_features': 500, 'n_estimators': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.979831</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>21</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998326</td>\n",
       "      <td>0.002050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>{'max_features': 500, 'n_estimators': 10}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>{'max_features': 500, 'n_estimators': 20}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995833</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>{'max_features': 500, 'n_estimators': 50}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.986554</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>{'max_features': 500, 'n_estimators': 100}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.983164</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  split0_test_score  \\\n",
       "0       {'max_features': 5, 'n_estimators': 5}                1.0   \n",
       "1      {'max_features': 5, 'n_estimators': 10}                1.0   \n",
       "2      {'max_features': 5, 'n_estimators': 20}                1.0   \n",
       "3      {'max_features': 5, 'n_estimators': 50}                1.0   \n",
       "4     {'max_features': 5, 'n_estimators': 100}                1.0   \n",
       "5      {'max_features': 10, 'n_estimators': 5}                1.0   \n",
       "6     {'max_features': 10, 'n_estimators': 10}                1.0   \n",
       "7     {'max_features': 10, 'n_estimators': 20}                1.0   \n",
       "8     {'max_features': 10, 'n_estimators': 50}                1.0   \n",
       "9    {'max_features': 10, 'n_estimators': 100}                1.0   \n",
       "10     {'max_features': 20, 'n_estimators': 5}                1.0   \n",
       "11    {'max_features': 20, 'n_estimators': 10}                1.0   \n",
       "12    {'max_features': 20, 'n_estimators': 20}                1.0   \n",
       "13    {'max_features': 20, 'n_estimators': 50}                1.0   \n",
       "14   {'max_features': 20, 'n_estimators': 100}                1.0   \n",
       "15     {'max_features': 50, 'n_estimators': 5}                1.0   \n",
       "16    {'max_features': 50, 'n_estimators': 10}                1.0   \n",
       "17    {'max_features': 50, 'n_estimators': 20}                1.0   \n",
       "18    {'max_features': 50, 'n_estimators': 50}                1.0   \n",
       "19   {'max_features': 50, 'n_estimators': 100}                1.0   \n",
       "20    {'max_features': 100, 'n_estimators': 5}                1.0   \n",
       "21   {'max_features': 100, 'n_estimators': 10}                1.0   \n",
       "22   {'max_features': 100, 'n_estimators': 20}                1.0   \n",
       "23   {'max_features': 100, 'n_estimators': 50}                1.0   \n",
       "24  {'max_features': 100, 'n_estimators': 100}                1.0   \n",
       "25    {'max_features': 200, 'n_estimators': 5}                1.0   \n",
       "26   {'max_features': 200, 'n_estimators': 10}                1.0   \n",
       "27   {'max_features': 200, 'n_estimators': 20}                1.0   \n",
       "28   {'max_features': 200, 'n_estimators': 50}                1.0   \n",
       "29  {'max_features': 200, 'n_estimators': 100}                1.0   \n",
       "30    {'max_features': 500, 'n_estimators': 5}                1.0   \n",
       "31   {'max_features': 500, 'n_estimators': 10}                1.0   \n",
       "32   {'max_features': 500, 'n_estimators': 20}                1.0   \n",
       "33   {'max_features': 500, 'n_estimators': 50}                1.0   \n",
       "34  {'max_features': 500, 'n_estimators': 100}                1.0   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.983333           1.000000           0.933333   \n",
       "1            1.000000           0.983333           0.950000   \n",
       "2            1.000000           1.000000           0.966667   \n",
       "3            1.000000           1.000000           0.966667   \n",
       "4            1.000000           1.000000           0.966667   \n",
       "5            0.983333           0.983333           0.950000   \n",
       "6            0.966667           1.000000           0.966667   \n",
       "7            1.000000           1.000000           0.966667   \n",
       "8            1.000000           1.000000           0.966667   \n",
       "9            1.000000           1.000000           0.966667   \n",
       "10           0.983333           1.000000           0.966667   \n",
       "11           1.000000           0.983333           0.966667   \n",
       "12           1.000000           1.000000           0.966667   \n",
       "13           1.000000           1.000000           0.966667   \n",
       "14           1.000000           1.000000           0.966667   \n",
       "15           1.000000           1.000000           0.950000   \n",
       "16           1.000000           1.000000           0.966667   \n",
       "17           1.000000           1.000000           0.966667   \n",
       "18           1.000000           1.000000           0.966667   \n",
       "19           1.000000           1.000000           0.966667   \n",
       "20           1.000000           1.000000           0.983333   \n",
       "21           1.000000           1.000000           0.950000   \n",
       "22           1.000000           1.000000           0.966667   \n",
       "23           1.000000           1.000000           0.966667   \n",
       "24           1.000000           1.000000           0.966667   \n",
       "25           1.000000           0.983333           0.966667   \n",
       "26           1.000000           0.983333           0.966667   \n",
       "27           1.000000           1.000000           0.966667   \n",
       "28           1.000000           1.000000           0.966667   \n",
       "29           1.000000           1.000000           0.966667   \n",
       "30           1.000000           1.000000           0.950000   \n",
       "31           1.000000           1.000000           0.966667   \n",
       "32           1.000000           1.000000           0.966667   \n",
       "33           1.000000           1.000000           0.966667   \n",
       "34           1.000000           1.000000           0.966667   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.898305         0.962994        0.040539               35   \n",
       "1            0.915254         0.969718        0.032786               33   \n",
       "2            0.949153         0.983164        0.021351                4   \n",
       "3            0.949153         0.983164        0.021351                4   \n",
       "4            0.949153         0.983164        0.021351                4   \n",
       "5            0.915254         0.966384        0.030290               34   \n",
       "6            0.932203         0.973107        0.025308               31   \n",
       "7            0.915254         0.976384        0.033180               29   \n",
       "8            0.949153         0.983164        0.021351                4   \n",
       "9            0.949153         0.983164        0.021351                4   \n",
       "10           0.949153         0.979831        0.019699               21   \n",
       "11           0.932203         0.976441        0.025338               26   \n",
       "12           0.949153         0.983164        0.021351                4   \n",
       "13           0.949153         0.983164        0.021351                4   \n",
       "14           0.949153         0.983164        0.021351                4   \n",
       "15           0.915254         0.973051        0.034787               32   \n",
       "16           0.915254         0.976384        0.033180               29   \n",
       "17           0.932203         0.979774        0.027063               24   \n",
       "18           0.932203         0.979774        0.027063               24   \n",
       "19           0.949153         0.983164        0.021351                4   \n",
       "20           0.949153         0.986497        0.019757                3   \n",
       "21           0.932203         0.976441        0.029398               26   \n",
       "22           0.949153         0.983164        0.021351                4   \n",
       "23           0.949153         0.983164        0.021351                4   \n",
       "24           0.949153         0.983164        0.021351                4   \n",
       "25           0.949153         0.979831        0.019699               21   \n",
       "26           0.932203         0.976441        0.025338               26   \n",
       "27           0.949153         0.983164        0.021351                4   \n",
       "28           0.949153         0.983164        0.021351                4   \n",
       "29           0.949153         0.983164        0.021351                4   \n",
       "30           0.949153         0.979831        0.024704               21   \n",
       "31           0.966102         0.986554        0.016469                1   \n",
       "32           0.949153         0.983164        0.021351                4   \n",
       "33           0.966102         0.986554        0.016469                1   \n",
       "34           0.949153         0.983164        0.021351                4   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0             1.000000            0.991632            0.991632   \n",
       "1             1.000000            1.000000            0.991632   \n",
       "2             0.995816            1.000000            1.000000   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5             0.995816            1.000000            0.987448   \n",
       "6             1.000000            1.000000            0.995816   \n",
       "7             1.000000            0.995816            1.000000   \n",
       "8             1.000000            1.000000            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            0.987448            0.995816            0.995816   \n",
       "11            1.000000            1.000000            0.991632   \n",
       "12            1.000000            1.000000            0.995816   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            0.991632            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17            1.000000            1.000000            1.000000   \n",
       "18            1.000000            1.000000            1.000000   \n",
       "19            1.000000            1.000000            1.000000   \n",
       "20            1.000000            0.995816            1.000000   \n",
       "21            0.995816            1.000000            0.991632   \n",
       "22            1.000000            0.995816            0.995816   \n",
       "23            1.000000            1.000000            1.000000   \n",
       "24            1.000000            1.000000            1.000000   \n",
       "25            1.000000            0.995816            0.991632   \n",
       "26            1.000000            1.000000            1.000000   \n",
       "27            1.000000            1.000000            1.000000   \n",
       "28            1.000000            1.000000            0.995816   \n",
       "29            1.000000            1.000000            1.000000   \n",
       "30            0.995816            0.995816            1.000000   \n",
       "31            1.000000            1.000000            1.000000   \n",
       "32            1.000000            1.000000            0.995816   \n",
       "33            1.000000            1.000000            1.000000   \n",
       "34            1.000000            1.000000            1.000000   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.995816            1.000000          0.995816         0.003742  \n",
       "1             0.995816            0.995833          0.996656         0.003130  \n",
       "2             1.000000            1.000000          0.999163         0.001674  \n",
       "3             1.000000            1.000000          1.000000         0.000000  \n",
       "4             1.000000            1.000000          1.000000         0.000000  \n",
       "5             1.000000            0.995833          0.995819         0.004583  \n",
       "6             1.000000            1.000000          0.999163         0.001674  \n",
       "7             1.000000            1.000000          0.999163         0.001674  \n",
       "8             1.000000            1.000000          1.000000         0.000000  \n",
       "9             1.000000            1.000000          1.000000         0.000000  \n",
       "10            0.995816            0.995833          0.994146         0.003349  \n",
       "11            1.000000            1.000000          0.998326         0.003347  \n",
       "12            1.000000            1.000000          0.999163         0.001674  \n",
       "13            1.000000            1.000000          1.000000         0.000000  \n",
       "14            1.000000            1.000000          1.000000         0.000000  \n",
       "15            1.000000            0.995833          0.997493         0.003346  \n",
       "16            1.000000            1.000000          1.000000         0.000000  \n",
       "17            1.000000            1.000000          1.000000         0.000000  \n",
       "18            1.000000            1.000000          1.000000         0.000000  \n",
       "19            1.000000            1.000000          1.000000         0.000000  \n",
       "20            1.000000            1.000000          0.999163         0.001674  \n",
       "21            1.000000            0.995833          0.996656         0.003130  \n",
       "22            1.000000            1.000000          0.998326         0.002050  \n",
       "23            1.000000            1.000000          1.000000         0.000000  \n",
       "24            1.000000            1.000000          1.000000         0.000000  \n",
       "25            1.000000            0.995833          0.996656         0.003130  \n",
       "26            1.000000            1.000000          1.000000         0.000000  \n",
       "27            1.000000            1.000000          1.000000         0.000000  \n",
       "28            1.000000            1.000000          0.999163         0.001674  \n",
       "29            1.000000            1.000000          1.000000         0.000000  \n",
       "30            1.000000            1.000000          0.998326         0.002050  \n",
       "31            1.000000            1.000000          1.000000         0.000000  \n",
       "32            1.000000            0.995833          0.998330         0.002046  \n",
       "33            1.000000            1.000000          1.000000         0.000000  \n",
       "34            1.000000            1.000000          1.000000         0.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_cvres.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "      <th>Gene ID</th>\n",
       "      <th>Gene Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.098663</td>\n",
       "      <td>ENSG00000171877</td>\n",
       "      <td>FRMD5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.098647</td>\n",
       "      <td>ENSG00000227376</td>\n",
       "      <td>FTH1P16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.096065</td>\n",
       "      <td>ENSG00000214653</td>\n",
       "      <td>HNRNPA3P3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.096062</td>\n",
       "      <td>ENSG00000242262</td>\n",
       "      <td>RP11-100N21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.095996</td>\n",
       "      <td>ENSG00000228797</td>\n",
       "      <td>FAM207BP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.093489</td>\n",
       "      <td>ENSG00000215102</td>\n",
       "      <td>TERF1P4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.093420</td>\n",
       "      <td>ENSG00000106367</td>\n",
       "      <td>AP1S1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.092276</td>\n",
       "      <td>ENSG00000213757</td>\n",
       "      <td>CTC-451P13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.089732</td>\n",
       "      <td>ENSG00000236603</td>\n",
       "      <td>RANP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.089540</td>\n",
       "      <td>ENSG00000224520</td>\n",
       "      <td>KRT8P45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature Importance          Gene ID      Gene Name\n",
       "0            0.098663  ENSG00000171877          FRMD5\n",
       "1            0.098647  ENSG00000227376        FTH1P16\n",
       "2            0.096065  ENSG00000214653      HNRNPA3P3\n",
       "3            0.096062  ENSG00000242262  RP11-100N21.1\n",
       "4            0.095996  ENSG00000228797       FAM207BP\n",
       "5            0.093489  ENSG00000215102        TERF1P4\n",
       "6            0.093420  ENSG00000106367          AP1S1\n",
       "7            0.092276  ENSG00000213757   CTC-451P13.1\n",
       "8            0.089732  ENSG00000236603          RANP1\n",
       "9            0.089540  ENSG00000224520        KRT8P45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tree_feature_importances.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Best Model on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       1.00      0.97      0.99        38\n",
      "       tumor       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.99        75\n",
      "   macro avg       0.99      0.99      0.99        75\n",
      "weighted avg       0.99      0.99      0.99        75\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      normal       1.00      0.97      0.99        38\n",
      "       tumor       0.97      1.00      0.99        37\n",
      "\n",
      "    accuracy                           0.99        75\n",
      "   macro avg       0.99      0.99      0.99        75\n",
      "weighted avg       0.99      0.99      0.99        75\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################\n",
    "# SCALE TEST DATA \n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "# EVALUATE LINEAR SVC MODEL\n",
    "svc_model = svc_search.best_estimator_\n",
    "y_svc_predictions = svc_model.predict(scaled_X_test)\n",
    "print(classification_report(y_test, y_svc_predictions, target_names=['normal', 'tumor']))\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "# EVALUATE RANDOM FOREST MODEL\n",
    "tree_model = tree_search.best_estimator_\n",
    "# make predictions\n",
    "y_tree_predictions = tree_model.predict(scaled_X_test)\n",
    "# evaluate predictions\n",
    "print(classification_report(y_test, y_tree_predictions, target_names=['normal', 'tumor']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews CorrelationCoefficient on predictions with SVC 0.97\n",
      "Matthews CorrelationCoefficient on predictions with Random Forest 0.97\n",
      "Balanced Accuracy score 0.99\n",
      "Balanced Accuracy score 0.99\n"
     ]
    }
   ],
   "source": [
    "print(\"Matthews CorrelationCoefficient on predictions with SVC %.2f\" %(matthews_corrcoef(y_test, y_svc_predictions)))\n",
    "print(\"Matthews CorrelationCoefficient on predictions with Random Forest %.2f\" %(matthews_corrcoef(y_test, y_tree_predictions)))\n",
    "\n",
    "print(\"Balanced Accuracy score %.2f\" %(balanced_accuracy_score(y_test, y_svc_predictions)))\n",
    "print(\"Balanced Accuracy score %.2f\" %(balanced_accuracy_score(y_test, y_tree_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confustion Matrix, ROC, AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Confusion Matrix\n",
      "[[37  1]\n",
      " [ 0 37]]\n",
      "Tree Confusion Matrix\n",
      "[[37  1]\n",
      " [ 0 37]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'ROC curve comparison')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "######################################################################################################\n",
    "# # EVALUATE LINEAR SVC MODEL\n",
    "disp_svc = plot_confusion_matrix(svc_model, scaled_X_test, y_test,\n",
    "                             display_labels=('control', 'tumor'),\n",
    "                              cmap=plt.cm.Blues)\n",
    "\n",
    "\n",
    "disp_svc.ax_.set_title('SVC Confusion Matrix')\n",
    "print('SVC Confusion Matrix')\n",
    "print(disp_svc.confusion_matrix)\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "# EVALUATE RANDOM FOREST MODEL\n",
    "disp_tree = plot_confusion_matrix(tree_model, scaled_X_test, y_test,\n",
    "                             display_labels=('control', 'tumor'),\n",
    "                              cmap=plt.cm.Blues)\n",
    "\n",
    "\n",
    "disp_tree.ax_.set_title('Tree Confusion Matrix')\n",
    "print('Tree Confusion Matrix')\n",
    "print(disp_tree.confusion_matrix)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################################################################\n",
    "# ROC AUC\n",
    "#svc_disp = plot_roc_curve(svc_search, scaled_X_test, y_test, name='SVC')\n",
    "tree_disp = plot_roc_curve(tree_search, scaled_X_test, y_test, name='RandomForest') # ax=svc_disp.ax_\n",
    "plt.title(\"ROC curve comparison\")\n",
    "# tree_disp.figure_.suptitle(\"ROC curve comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
